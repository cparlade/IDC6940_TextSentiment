{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5253d78",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import time, pathlib, numpy as np, pandas as pd, torch\n",
    "from datasets import Dataset\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer)\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "DATA_DIR = pathlib.Path(\"data/processed\")\n",
    "train_df = pd.read_csv(DATA_DIR/\"phrasebank_train.csv\")\n",
    "test_df  = pd.read_csv(DATA_DIR/\"phrasebank_test.csv\")\n",
    "\n",
    "id2label = {0:'negative',1:'neutral',2:'positive'}\n",
    "label2id = {v:k for k,v in id2label.items()}\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "def tokenize(batch):\n",
    "    return tok(batch[\"sentence\"], truncation=True, padding=\"max_length\", max_length=64)\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df[['sentence','label']].rename(columns={'label':'labels'}))\n",
    "test_ds  = Dataset.from_pandas(test_df [['sentence','label']].rename(columns={'label':'labels'}))\n",
    "train_ds = train_ds.map(tokenize, batched=True)\n",
    "test_ds  = test_ds.map(tokenize, batched=True)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"ProsusAI/finbert\", num_labels=3, id2label=id2label, label2id=label2id)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"finbert-ft\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=1,\n",
    "    logging_steps=50,\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(-1)\n",
    "    return {\n",
    "        \"f1\": f1_score(labels, preds, average=\"macro\"),\n",
    "        \"acc\": accuracy_score(labels, preds)\n",
    "    }\n",
    "\n",
    "trainer = Trainer(model=model, args=args, train_dataset=train_ds, eval_dataset=test_ds, compute_metrics=compute_metrics)\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "trainer.train()\n",
    "train_time_s = time.perf_counter() - t0\n",
    "\n",
    "# Inference on test set\n",
    "pred_logits = trainer.predict(test_ds).predictions\n",
    "pred_ids = pred_logits.argmax(-1)\n",
    "pred_labels = pd.Series(pred_ids).map(id2label)\n",
    "\n",
    "out = test_df.copy()\n",
    "out['pred'] = pred_labels.values\n",
    "out.to_csv(DATA_DIR/\"finbert_preds.csv\", index=False)\n",
    "\n",
    "macro_f1 = f1_score(test_df['label'], pred_ids, average='macro')\n",
    "acc = accuracy_score(test_df['label'], pred_ids)\n",
    "print(f\"FinBERT  macro-F1={macro_f1:.3f}  acc={acc:.3f}  train_time={train_time_s/60:.1f} min\")\n",
    "print(confusion_matrix(test_df['label'], pred_ids, labels=[0,1,2]))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
